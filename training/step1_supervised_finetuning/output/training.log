[2023-07-30 22:19:18,198] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-07-30 22:19:19,477] [WARNING] [runner.py:201:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-07-30 22:19:19,560] [INFO] [runner.py:567:main] cmd = /root/miniconda3/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None main.py --data_path /root/selfChatTrain/generateData --data_split 10,0,0 --model_name_or_path facebook/opt-1.3b --per_device_train_batch_size 8 --per_device_eval_batch_size 8 --max_seq_len 512 --learning_rate 1e-3 --weight_decay 0.1 --num_train_epochs 16 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --num_warmup_steps 0 --seed 1234 --zero_stage 0 --lora_dim 128 --lora_module_name decoder.layers. --only_optimize_lora --deepspeed --output_dir ./output
[2023-07-30 22:19:20,786] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-07-30 22:19:22,003] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}
[2023-07-30 22:19:22,003] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-07-30 22:19:22,003] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-07-30 22:19:22,003] [INFO] [launch.py:163:main] dist_world_size=1
[2023-07-30 22:19:22,003] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0
[2023-07-30 22:19:23,728] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-07-30 22:19:25,701] [INFO] [comm.py:631:init_distributed] cdb=None
[2023-07-30 22:19:25,701] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 685/685 [00:00<00:00, 6.18MB/s]
Downloading (…)lve/main/config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 653/653 [00:00<00:00, 6.38MB/s]
Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 981kB/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 981kB/s]
Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 3.22MB/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 3.21MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 441/441 [00:00<00:00, 4.07MB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/2.63G [00:00<?, ?B/s]Downloading pytorch_model.bin:   0%|          | 10.5M/2.63G [00:02<09:05, 4.81MB/s]Downloading pytorch_model.bin:   1%|          | 21.0M/2.63G [00:02<05:43, 7.61MB/s]Downloading pytorch_model.bin:   1%|          | 31.5M/2.63G [00:04<05:04, 8.54MB/s]Downloading pytorch_model.bin:   2%|▏         | 41.9M/2.63G [00:04<04:32, 9.50MB/s]Downloading pytorch_model.bin:   2%|▏         | 52.4M/2.63G [00:05<03:49, 11.2MB/s]Downloading pytorch_model.bin:   2%|▏         | 62.9M/2.63G [00:06<03:24, 12.6MB/s]Downloading pytorch_model.bin:   3%|▎         | 73.4M/2.63G [00:07<03:34, 11.9MB/s]Downloading pytorch_model.bin:   3%|▎         | 83.9M/2.63G [00:08<03:37, 11.7MB/s]Downloading pytorch_model.bin:   4%|▎         | 94.4M/2.63G [00:08<03:17, 12.8MB/s]Downloading pytorch_model.bin:   4%|▍         | 105M/2.63G [00:09<03:24, 12.3MB/s] Downloading pytorch_model.bin:   4%|▍         | 115M/2.63G [00:10<03:28, 12.1MB/s]Downloading pytorch_model.bin:   5%|▍         | 126M/2.63G [00:11<03:45, 11.1MB/s]Downloading pytorch_model.bin:   5%|▌         | 136M/2.63G [00:12<03:57, 10.5MB/s]Downloading pytorch_model.bin:   6%|▌         | 147M/2.63G [00:14<04:16, 9.68MB/s]Downloading pytorch_model.bin:   6%|▌         | 157M/2.63G [00:15<04:11, 9.83MB/s]Downloading pytorch_model.bin:   6%|▋         | 168M/2.63G [00:15<03:44, 11.0MB/s]Downloading pytorch_model.bin:   7%|▋         | 178M/2.63G [00:16<03:39, 11.2MB/s]Downloading pytorch_model.bin:   7%|▋         | 189M/2.63G [00:17<03:37, 11.3MB/s]Downloading pytorch_model.bin:   8%|▊         | 199M/2.63G [00:18<03:16, 12.4MB/s]Downloading pytorch_model.bin:   8%|▊         | 210M/2.63G [00:19<03:19, 12.1MB/s]Downloading pytorch_model.bin:   8%|▊         | 220M/2.63G [00:20<03:19, 12.1MB/s]Downloading pytorch_model.bin:   9%|▉         | 231M/2.63G [00:20<03:04, 13.0MB/s]Downloading pytorch_model.bin:   9%|▉         | 241M/2.63G [00:21<03:08, 12.7MB/s]Downloading pytorch_model.bin:  10%|▉         | 252M/2.63G [00:22<03:11, 12.4MB/s]Downloading pytorch_model.bin:  10%|▉         | 262M/2.63G [00:23<03:53, 10.1MB/s]Downloading pytorch_model.bin:  10%|█         | 273M/2.63G [00:24<03:47, 10.4MB/s]Downloading pytorch_model.bin:  11%|█         | 283M/2.63G [00:26<03:52, 10.1MB/s]Downloading pytorch_model.bin:  11%|█         | 294M/2.63G [00:26<03:40, 10.6MB/s]Downloading pytorch_model.bin:  12%|█▏        | 304M/2.63G [00:27<03:25, 11.3MB/s]Downloading pytorch_model.bin:  12%|█▏        | 315M/2.63G [00:28<03:25, 11.3MB/s]Downloading pytorch_model.bin:  12%|█▏        | 325M/2.63G [00:29<03:23, 11.3MB/s]Downloading pytorch_model.bin:  13%|█▎        | 336M/2.63G [00:30<03:13, 11.8MB/s]Downloading pytorch_model.bin:  13%|█▎        | 346M/2.63G [00:31<03:29, 10.9MB/s]Downloading pytorch_model.bin:  14%|█▎        | 357M/2.63G [00:32<03:28, 10.9MB/s]Downloading pytorch_model.bin:  14%|█▍        | 367M/2.63G [00:33<03:29, 10.8MB/s]Downloading pytorch_model.bin:  14%|█▍        | 377M/2.63G [00:34<03:25, 11.0MB/s]Downloading pytorch_model.bin:  15%|█▍        | 388M/2.63G [00:35<03:24, 11.0MB/s]Downloading pytorch_model.bin:  15%|█▌        | 398M/2.63G [00:36<04:05, 9.09MB/s]Downloading pytorch_model.bin:  16%|█▌        | 409M/2.63G [00:37<03:40, 10.1MB/s]Downloading pytorch_model.bin:  16%|█▌        | 419M/2.63G [00:38<03:29, 10.5MB/s]Downloading pytorch_model.bin:  16%|█▋        | 430M/2.63G [00:39<03:28, 10.5MB/s]Downloading pytorch_model.bin:  17%|█▋        | 440M/2.63G [00:40<03:04, 11.9MB/s]Downloading pytorch_model.bin:  17%|█▋        | 451M/2.63G [00:41<03:04, 11.8MB/s]Downloading pytorch_model.bin:  18%|█▊        | 461M/2.63G [00:42<03:15, 11.1MB/s]Downloading pytorch_model.bin:  18%|█▊        | 472M/2.63G [00:42<02:56, 12.3MB/s]Downloading pytorch_model.bin:  18%|█▊        | 482M/2.63G [00:43<02:59, 12.0MB/s]Downloading pytorch_model.bin:  19%|█▊        | 493M/2.63G [00:44<03:01, 11.8MB/s]Downloading pytorch_model.bin:  19%|█▉        | 503M/2.63G [00:45<02:58, 11.9MB/s]Downloading pytorch_model.bin:  20%|█▉        | 514M/2.63G [00:46<02:49, 12.5MB/s]Downloading pytorch_model.bin:  20%|█▉        | 524M/2.63G [00:47<03:39, 9.62MB/s]Downloading pytorch_model.bin:  20%|██        | 535M/2.63G [00:48<03:30, 9.95MB/s]Downloading pytorch_model.bin:  21%|██        | 545M/2.63G [00:49<03:03, 11.4MB/s]Downloading pytorch_model.bin:  21%|██        | 556M/2.63G [00:50<03:18, 10.5MB/s]Downloading pytorch_model.bin:  22%|██▏       | 566M/2.63G [00:51<03:09, 10.9MB/s]Downloading pytorch_model.bin:  22%|██▏       | 577M/2.63G [00:52<02:53, 11.8MB/s]Downloading pytorch_model.bin:  22%|██▏       | 587M/2.63G [00:53<02:54, 11.7MB/s]Downloading pytorch_model.bin:  23%|██▎       | 598M/2.63G [00:53<02:40, 12.7MB/s]Downloading pytorch_model.bin:  23%|██▎       | 608M/2.63G [00:54<02:44, 12.3MB/s]Downloading pytorch_model.bin:  24%|██▎       | 619M/2.63G [00:55<02:48, 11.9MB/s]Downloading pytorch_model.bin:  24%|██▍       | 629M/2.63G [00:56<02:33, 13.0MB/s]Downloading pytorch_model.bin:  24%|██▍       | 640M/2.63G [00:57<02:39, 12.5MB/s]Downloading pytorch_model.bin:  25%|██▍       | 650M/2.63G [00:58<03:07, 10.6MB/s][2023-07-30 22:20:32,568] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 520960
[2023-07-30 22:20:32,704] [INFO] [launch.py:324:sigkill_handler] Main process received SIGINT, exiting
Error in sys.excepthook:
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1694, in print
    extend(render(renderable, render_options))
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/root/miniconda3/lib/python3.10/site-packages/rich/constrain.py", line 29, in __rich_console__
    yield from console.render(self.renderable, child_options)
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/root/miniconda3/lib/python3.10/site-packages/rich/panel.py", line 220, in __rich_console__
    lines = console.render_lines(renderable, child_options, style=style)
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/root/miniconda3/lib/python3.10/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/root/miniconda3/lib/python3.10/site-packages/rich/padding.py", line 97, in __rich_console__
    lines = console.render_lines(
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1366, in render_lines
    lines = list(
  File "/root/miniconda3/lib/python3.10/site-packages/rich/segment.py", line 292, in split_and_crop_lines
    for segment in segments:
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1330, in render
    yield from self.render(render_output, _options)
  File "/root/miniconda3/lib/python3.10/site-packages/rich/console.py", line 1326, in render
    for render_output in iter_render:
  File "/root/miniconda3/lib/python3.10/site-packages/rich/syntax.py", line 609, in __rich_console__
    segments = Segments(self._get_syntax(console, options))
  File "/root/miniconda3/lib/python3.10/site-packages/rich/segment.py", line 668, in __init__
    self.segments = list(segments)
  File "/root/miniconda3/lib/python3.10/site-packages/rich/syntax.py", line 637, in _get_syntax
    text = self.highlight(processed_code, self.line_range)
  File "/root/miniconda3/lib/python3.10/site-packages/rich/syntax.py", line 509, in highlight
    text.append_tokens(tokens_to_spans())
  File "/root/miniconda3/lib/python3.10/site-packages/rich/text.py", line 995, in append_tokens
    for content, style in tokens:
  File "/root/miniconda3/lib/python3.10/site-packages/rich/syntax.py", line 497, in tokens_to_spans
    _token_type, token = next(tokens)
  File "/root/miniconda3/lib/python3.10/site-packages/rich/syntax.py", line 484, in line_tokenize
    for token_type, token in lexer.get_tokens(code):
  File "/root/miniconda3/lib/python3.10/site-packages/pygments/lexer.py", line 250, in streamer
    for _, t, v in self.get_tokens_unprocessed(text):
  File "/root/miniconda3/lib/python3.10/site-packages/pygments/lexer.py", line 693, in get_tokens_unprocessed
    m = rexmatch(text, pos)
KeyboardInterrupt

Original exception was:
Traceback (most recent call last):
  File "/root/miniconda3/bin/deepspeed", line 6, in <module>
    main()
  File "/root/miniconda3/lib/python3.10/site-packages/deepspeed/launcher/runner.py", line 582, in main
    result.wait()
  File "/root/miniconda3/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/root/miniconda3/lib/python3.10/subprocess.py", line 1943, in _wait
    (pid, sts) = self._try_wait(0)
  File "/root/miniconda3/lib/python3.10/subprocess.py", line 1901, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
